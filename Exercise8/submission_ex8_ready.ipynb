{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T17:54:26.379397Z",
     "start_time": "2025-11-28T17:54:24.674703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score, mean_absolute_error\n",
    "from sklearn.manifold import TSNE\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "\n",
    "# ---------- USER SETTINGS ----------\n",
    "PATIENT_CSV = \"patient-data.csv\"\n",
    "MNIST_CSV = \"mnist_test_nolabels.csv\"   # set to None if not available\n",
    "CURSE_XLSX = \"curse-of-dimensionality.xlsx\"\n",
    "TARGET_COLUMN = \"Ailment\"  # detected automatically earlier; change if incorrect\n",
    "FORCE_TASK = None  # 'classification' or 'regression' or None\n",
    "\n",
    "OUT_DIR = \"submission_outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def compute_vif(df):\n",
    "    X = df.select_dtypes(include=[np.number]).copy()\n",
    "    X = X.dropna(axis=1, how='all')\n",
    "    if X.shape[1] < 2:\n",
    "        return pd.DataFrame(columns=['feature','VIF'])\n",
    "    Xc = sm.add_constant(X)\n",
    "    vif = []\n",
    "    for i, col in enumerate(X.columns):\n",
    "        try:\n",
    "            v = variance_inflation_factor(Xc.values, i+1)\n",
    "        except Exception:\n",
    "            v = float('nan')\n",
    "        vif.append((col, float(v)))\n",
    "    return pd.DataFrame(vif, columns=['feature','VIF']).sort_values('VIF', ascending=False)\n",
    "\n",
    "def basic_preprocess(df, target_col=None, drop_cols=None):\n",
    "    df = df.copy()\n",
    "    if drop_cols:\n",
    "        for c in drop_cols:\n",
    "            if c in df.columns:\n",
    "                df = df.drop(columns=c)\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except:\n",
    "            df[col] = df[col].astype('category').cat.codes\n",
    "    if target_col is not None:\n",
    "        df = df.dropna(subset=[target_col])\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    path = os.path.join(OUT_DIR, name)\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=150)\n",
    "    print(\"Saved figure:\", path)\n",
    "\n",
    "def main():\n",
    "    # Load patient data\n",
    "    if not os.path.exists(PATIENT_CSV):\n",
    "        # try alternative names in cwd\n",
    "        candidates = [f for f in os.listdir('.') if f.lower().startswith('patient') and f.lower().endswith('.csv')]\n",
    "        if candidates:\n",
    "            print(\"Using alternative patient CSV:\", candidates[0])\n",
    "            patient_file = candidates[0]\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Patient CSV '{PATIENT_CSV}' not found in working dir.\")\n",
    "    else:\n",
    "        patient_file = PATIENT_CSV\n",
    "    print(\"Loading patient file:\", patient_file)\n",
    "    df = pd.read_csv(patient_file)\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "    # Determine target\n",
    "    TARGET = TARGET_COLUMN if TARGET_COLUMN in df.columns else None\n",
    "    if TARGET is None:\n",
    "        # fallback heuristics\n",
    "        prefs = ['Outcome','outcome','target','Target','label','Label','Y','y','Diagnosis','diagnosis','Class','class','response','Response']\n",
    "        for c in prefs:\n",
    "            if c in df.columns:\n",
    "                TARGET = c\n",
    "                break\n",
    "    if TARGET is None:\n",
    "        TARGET = df.columns[-1]\n",
    "        print(\"Falling back to last column as target:\", TARGET)\n",
    "    print(\"Using target column:\", TARGET)\n",
    "\n",
    "    # Preprocess\n",
    "    df_p = basic_preprocess(df, target_col=TARGET)\n",
    "    print(\"After preprocessing shape:\", df_p.shape)\n",
    "    print(\"Target unique values:\", df_p[TARGET].nunique())\n",
    "\n",
    "    # Detect task\n",
    "    n_unique = df_p[TARGET].nunique(dropna=True)\n",
    "    if FORCE_TASK in ('classification','regression'):\n",
    "        task = FORCE_TASK\n",
    "    else:\n",
    "        if (df_p[TARGET].dtype.kind in 'biufc' and n_unique > 20):\n",
    "            task = 'regression'\n",
    "        else:\n",
    "            task = 'classification'\n",
    "    print(\"Detected task:\", task)\n",
    "\n",
    "    # Correlation heatmap\n",
    "    num_df = df_p.select_dtypes(include=[np.number]).copy()\n",
    "    if TARGET in num_df.columns:\n",
    "        num_df = num_df.drop(columns=[TARGET])\n",
    "    corr = num_df.corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "    plt.title('Pairwise correlation heatmap (numeric features)')\n",
    "    heatmap_path = os.path.join(OUT_DIR, \"correlation_heatmap.png\")\n",
    "    plt.savefig(heatmap_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    print(\"Saved correlation heatmap to\", heatmap_path)\n",
    "\n",
    "    # VIF and progressive dropping\n",
    "    X = df_p.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
    "    y = df_p[TARGET]\n",
    "    print(\"Numeric feature count:\", X.shape[1])\n",
    "    vif_df = compute_vif(X)\n",
    "    print(\"\\\\nTop VIFs:\\\\n\", vif_df.head(20).to_string(index=False))\n",
    "\n",
    "    # Progressive drop tracking\n",
    "    def eval_metric_for_model(est, Xmat, yvec, task):\n",
    "        try:\n",
    "            strat = yvec if (task=='classification' and len(np.unique(yvec))>2) else None\n",
    "            Xtr, Xte, ytr, yte = train_test_split(Xmat, yvec, test_size=0.25, random_state=42, stratify=strat)\n",
    "        except Exception:\n",
    "            Xtr, Xte, ytr, yte = train_test_split(Xmat, yvec, test_size=0.25, random_state=42)\n",
    "        sc = StandardScaler(); Xtr_s = sc.fit_transform(Xtr); Xte_s = sc.transform(Xte)\n",
    "        est.fit(Xtr_s, ytr)\n",
    "        yp = est.predict(Xte_s)\n",
    "        if task=='classification':\n",
    "            return float(f1_score(yte, np.round(yp), average='weighted', zero_division=0))\n",
    "        else:\n",
    "            return float(r2_score(yte, yp))\n",
    "\n",
    "    history = []\n",
    "    X_work = X.copy()\n",
    "    step = 0\n",
    "    est = RandomForestClassifier(n_estimators=100, random_state=0) if task=='classification' else RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    while True:\n",
    "        vif_now = compute_vif(X_work)\n",
    "        metric_now = eval_metric_for_model(est, X_work, y, task)\n",
    "        history.append({'step': step, 'n_features': X_work.shape[1], 'metric': metric_now, 'top_vif': vif_now.head(3)})\n",
    "        print(f\"Step {step}: features={X_work.shape[1]}, metric={metric_now:.4f}\")\n",
    "        if vif_now.empty:\n",
    "            break\n",
    "        maxv = vif_now['VIF'].iloc[0]\n",
    "        if pd.isna(maxv) or maxv <= 10 or X_work.shape[1] <= 2:\n",
    "            break\n",
    "        dropf = vif_now['feature'].iloc[0]\n",
    "        print(\" Dropping feature due to high VIF:\", dropf, \" (VIF=\", maxv, \")\")\n",
    "        X_work = X_work.drop(columns=[dropf])\n",
    "        step += 1\n",
    "\n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame([{'step':h['step'],'n_features':h['n_features'],'metric':h['metric']} for h in history])\n",
    "    hist_df.to_csv(os.path.join(OUT_DIR, \"vif_progression.csv\"), index=False)\n",
    "    print(\"Saved VIF progression to\", os.path.join(OUT_DIR, \"vif_progression.csv\"))\n",
    "\n",
    "    # PCA explained variance\n",
    "    Xnum = df_p.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
    "    sc = StandardScaler(); Xs = sc.fit_transform(Xnum)\n",
    "    pca = PCA(); pca.fit(Xs)\n",
    "    var_ratio = pca.explained_variance_ratio_\n",
    "    # plot variance and cumulative\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.bar(np.arange(1, len(var_ratio)+1), var_ratio)\n",
    "    plt.xlabel('PC'); plt.ylabel('Explained variance ratio'); plt.title('PCA: variance explained')\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"pca_variance.png\"), bbox_inches='tight', dpi=150); plt.close()\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(np.arange(1, len(var_ratio)+1), np.cumsum(var_ratio), marker='o')\n",
    "    plt.xlabel('PC'); plt.ylabel('Cumulative explained variance'); plt.title('PCA: cumulative explained')\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"pca_cumulative.png\"), bbox_inches='tight', dpi=150); plt.close()\n",
    "    print(\"Saved PCA variance plots to output folder.\")\n",
    "\n",
    "    # Models on top-k PCs vs original\n",
    "    Xp = pca.transform(Xs)\n",
    "    if task == 'classification':\n",
    "        base_est = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "        pcs = [2,3,5,10,20]\n",
    "    else:\n",
    "        base_est = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "        pcs = [2,3,5,10,20]\n",
    "\n",
    "    results = []\n",
    "    for k in [p for p in pcs if p <= Xp.shape[1]]:\n",
    "        Xk = Xp[:, :k]\n",
    "        try:\n",
    "            strat = y if (task=='classification' and len(np.unique(y))>2) else None\n",
    "            Xtr, Xte, ytr, yte = train_test_split(Xk, y, test_size=0.25, random_state=42, stratify=strat)\n",
    "        except Exception:\n",
    "            Xtr, Xte, ytr, yte = train_test_split(Xk, y, test_size=0.25, random_state=42)\n",
    "        base_est.fit(Xtr, ytr)\n",
    "        yp = base_est.predict(Xte)\n",
    "        if task=='classification':\n",
    "            res = {'k':k, 'f1': float(f1_score(yte, np.round(yp), average='weighted', zero_division=0)), 'accuracy': float(accuracy_score(yte, np.round(yp)))}\n",
    "        else:\n",
    "            res = {'k':k, 'r2': float(r2_score(yte, yp)), 'mae': float(mean_absolute_error(yte, yp))}\n",
    "        results.append(res)\n",
    "    # baseline original\n",
    "    try:\n",
    "        strat = y if (task=='classification' and len(np.unique(y))>2) else None\n",
    "        Xtr, Xte, ytr, yte = train_test_split(Xs, y, test_size=0.25, random_state=42, stratify=strat)\n",
    "    except Exception:\n",
    "        Xtr, Xte, ytr, yte = train_test_split(Xs, y, test_size=0.25, random_state=42)\n",
    "    base_est.fit(Xtr, ytr)\n",
    "    yp = base_est.predict(Xte)\n",
    "    if task=='classification':\n",
    "        base_res = {'k':'original', 'f1': float(f1_score(yte, np.round(yp), average='weighted', zero_division=0)), 'accuracy': float(accuracy_score(yte, np.round(yp)))}\n",
    "    else:\n",
    "        base_res = {'k':'original', 'r2': float(r2_score(yte, yp)), 'mae': float(mean_absolute_error(yte, yp))}\n",
    "    results.append(base_res)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(os.path.join(OUT_DIR, \"pca_model_results.csv\"), index=False)\n",
    "    print(\"Saved PCA model comparison to\", os.path.join(OUT_DIR, \"pca_model_results.csv\"))\n",
    "    print(results_df)\n",
    "\n",
    "    # MNIST part (if present)\n",
    "    if MNIST_CSV and os.path.exists(MNIST_CSV):\n",
    "        mn = pd.read_csv(MNIST_CSV, header=None)\n",
    "        print(\"MNIST shape:\", mn.shape)\n",
    "        sc = StandardScaler(); Xm = sc.fit_transform(mn)\n",
    "        pca_m = PCA(n_components=50); Xm_p = pca_m.fit_transform(Xm)\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.bar(np.arange(1,51), pca_m.explained_variance_ratio_); plt.title('MNIST: first 50 PC variance')\n",
    "        plt.savefig(os.path.join(OUT_DIR, \"mnist_pca_variance.png\"), bbox_inches='tight', dpi=150); plt.close()\n",
    "        plt.figure(figsize=(6,6)); plt.scatter(Xm_p[:,0], Xm_p[:,1], s=2, alpha=0.6); plt.xlabel('PC1'); plt.ylabel('PC2'); plt.title('MNIST PC1 vs PC2'); plt.savefig(os.path.join(OUT_DIR, \"mnist_pc1_pc2.png\"), bbox_inches='tight', dpi=150); plt.close()\n",
    "        subs = min(3000, Xm.shape[0])\n",
    "        idx = np.random.RandomState(42).choice(Xm.shape[0], subs, replace=False)\n",
    "        tsne = TSNE(n_components=2, init='pca', random_state=42, perplexity=30)\n",
    "        Xm_emb = tsne.fit_transform(Xm[idx])\n",
    "        plt.figure(figsize=(7,6)); plt.scatter(Xm_emb[:,0], Xm_emb[:,1], s=3, alpha=0.7); plt.title('t-SNE (mnist subsample)'); plt.savefig(os.path.join(OUT_DIR, \"mnist_tsne.png\"), bbox_inches='tight', dpi=150); plt.close()\n",
    "        print(\"Saved MNIST visualizations to output folder.\")\n",
    "\n",
    "    print(\"\\\\nAll done. Outputs saved in folder:\", OUT_DIR)\n",
    "    print(\"Files:\", os.listdir(OUT_DIR))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "df0ca78d3e2540b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading patient file: patient-data.csv\n",
      "Shape: (2371, 25)\n",
      "Columns: ['p01', 'p02', 'p03', 'p04', 'p05', 'p06', 'p07', 'p08', 'p09', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'Ailment']\n",
      "Using target column: Ailment\n",
      "After preprocessing shape: (2369, 25)\n",
      "Target unique values: 6\n",
      "Detected task: classification\n",
      "Saved correlation heatmap to submission_outputs\\correlation_heatmap.png\n",
      "Numeric feature count: 24\n",
      "\\nTop VIFs:\\n feature      VIF\n",
      "    p12 2.298896\n",
      "    p11 1.907719\n",
      "    p01 1.798676\n",
      "    p23 1.727740\n",
      "    p14 1.684002\n",
      "    p17 1.682450\n",
      "    p02 1.666927\n",
      "    p03 1.652836\n",
      "    p20 1.637955\n",
      "    p18 1.620127\n",
      "    p15 1.576903\n",
      "    p24 1.558440\n",
      "    p06 1.542741\n",
      "    p22 1.520029\n",
      "    p16 1.510267\n",
      "    p09 1.489615\n",
      "    p19 1.488772\n",
      "    p04 1.403903\n",
      "    p05 1.401024\n",
      "    p07 1.395304\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type str which has no callable rint method",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[31mAttributeError\u001B[39m: 'str' object has no attribute 'rint'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001B[39m, in \u001B[36m_wrapfunc\u001B[39m\u001B[34m(obj, method, *args, **kwds)\u001B[39m\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbound\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m     59\u001B[39m     \u001B[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001B[39;00m\n\u001B[32m     60\u001B[39m     \u001B[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     64\u001B[39m     \u001B[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001B[39;00m\n\u001B[32m     65\u001B[39m     \u001B[38;5;66;03m# exception has a traceback chain.\u001B[39;00m\n",
      "\u001B[31mTypeError\u001B[39m: loop of ufunc does not support argument 0 of type str which has no callable rint method",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[31mAttributeError\u001B[39m: 'str' object has no attribute 'rint'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 252\u001B[39m\n\u001B[32m    249\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFiles:\u001B[39m\u001B[33m\"\u001B[39m, os.listdir(OUT_DIR))\n\u001B[32m    251\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m'\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m252\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 155\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    154\u001B[39m     vif_now = compute_vif(X_work)\n\u001B[32m--> \u001B[39m\u001B[32m155\u001B[39m     metric_now = \u001B[43meval_metric_for_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_work\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    156\u001B[39m     history.append({\u001B[33m'\u001B[39m\u001B[33mstep\u001B[39m\u001B[33m'\u001B[39m: step, \u001B[33m'\u001B[39m\u001B[33mn_features\u001B[39m\u001B[33m'\u001B[39m: X_work.shape[\u001B[32m1\u001B[39m], \u001B[33m'\u001B[39m\u001B[33mmetric\u001B[39m\u001B[33m'\u001B[39m: metric_now, \u001B[33m'\u001B[39m\u001B[33mtop_vif\u001B[39m\u001B[33m'\u001B[39m: vif_now.head(\u001B[32m3\u001B[39m)})\n\u001B[32m    157\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mStep \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: features=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mX_work.shape[\u001B[32m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, metric=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_now\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 145\u001B[39m, in \u001B[36mmain.<locals>.eval_metric_for_model\u001B[39m\u001B[34m(est, Xmat, yvec, task)\u001B[39m\n\u001B[32m    143\u001B[39m yp = est.predict(Xte_s)\n\u001B[32m    144\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m task==\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m145\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(f1_score(yte, \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mround\u001B[49m\u001B[43m(\u001B[49m\u001B[43myp\u001B[49m\u001B[43m)\u001B[49m, average=\u001B[33m'\u001B[39m\u001B[33mweighted\u001B[39m\u001B[33m'\u001B[39m, zero_division=\u001B[32m0\u001B[39m))\n\u001B[32m    146\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    147\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(r2_score(yte, yp))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3710\u001B[39m, in \u001B[36mround\u001B[39m\u001B[34m(a, decimals, out)\u001B[39m\n\u001B[32m   3618\u001B[39m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_round_dispatcher)\n\u001B[32m   3619\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mround\u001B[39m(a, decimals=\u001B[32m0\u001B[39m, out=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m   3620\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   3621\u001B[39m \u001B[33;03m    Evenly round to the given number of decimals.\u001B[39;00m\n\u001B[32m   3622\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   3708\u001B[39m \n\u001B[32m   3709\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3710\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mround\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecimals\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecimals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:66\u001B[39m, in \u001B[36m_wrapfunc\u001B[39m\u001B[34m(obj, method, *args, **kwds)\u001B[39m\n\u001B[32m     57\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m bound(*args, **kwds)\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m     59\u001B[39m     \u001B[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001B[39;00m\n\u001B[32m     60\u001B[39m     \u001B[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     64\u001B[39m     \u001B[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001B[39;00m\n\u001B[32m     65\u001B[39m     \u001B[38;5;66;03m# exception has a traceback chain.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:46\u001B[39m, in \u001B[36m_wrapit\u001B[39m\u001B[34m(obj, method, *args, **kwds)\u001B[39m\n\u001B[32m     43\u001B[39m \u001B[38;5;66;03m# As this already tried the method, subok is maybe quite reasonable here\u001B[39;00m\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# but this follows what was done before. TODO: revisit this.\u001B[39;00m\n\u001B[32m     45\u001B[39m arr, = conv.as_arrays(subok=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m result = \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m conv.wrap(result, to_scalar=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[31mTypeError\u001B[39m: loop of ufunc does not support argument 0 of type str which has no callable rint method"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8cc76b86c0d94f71"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
